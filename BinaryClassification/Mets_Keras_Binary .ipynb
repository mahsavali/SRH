{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ7HCAoypV-L",
        "outputId": "7280ef21-4a7a-477f-ac60-ad0d8f7c5faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kthxQWZzRiow"
      },
      "outputs": [],
      "source": [
        "select_label = '0'\n",
        "path = 'D:\\SRHproject\\concat_images\\concat_images'\n",
        "image_size = 1024\n",
        "n_classes = 2 # for binary\n",
        "# n_classes  8\n",
        "learning_rate = 0.001\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lf_1xgmdqr4T"
      },
      "outputs": [],
      "source": [
        "class_names = {'adenocarcinoma': 0,\n",
        "            'hematopoietic ': 1,\n",
        "            'squamous cell carcinoma ': 2,\n",
        "            'melanoma': 3,\n",
        "            'sarcoma ': 4,\n",
        "            'neuroendocrine carcinoma ': 5,\n",
        "            'urothelial carcinoma ': 6,\n",
        "            'non-tumor':7}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSPyu-M8RqzT"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os, cv2, shutil\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import albumentations as album\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m_Va3F2tRrP6"
      },
      "outputs": [],
      "source": [
        "if not(os.path.exists(path)):\n",
        "    !unzip -q /content/drive/MyDrive/d1/concat_images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9HD8vHZSFkj",
        "outputId": "07730180-444c-428b-d959-157e8268af29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels\n",
            "0         340\n",
            "2          96\n",
            "3          60\n",
            "7          52\n",
            "1          50\n",
            "5          50\n",
            "4           8\n",
            "6           2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir(path)\n",
        "patients = []\n",
        "labels = []\n",
        "\n",
        "for f in files:\n",
        "    labels.append(f.split('_')[4])\n",
        "    p = f.split('_')[0]\n",
        "    c = f.split('_')[4]\n",
        "    if (p not in patients) and (c not in ['4', '6']):\n",
        "        patients.append(p)\n",
        "\n",
        "print(pd.DataFrame({'labels': labels}).value_counts())\n",
        "\n",
        "train_patients, valid_patients = train_test_split(patients, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0zfNckO5T-UC"
      },
      "outputs": [],
      "source": [
        "def prepare_data(path, splited_data, select_label):\n",
        "    all_files = os.listdir(path)\n",
        "\n",
        "    data = []\n",
        "    for t in splited_data:\n",
        "        for f in files:\n",
        "            if t == f.split('_')[0]:\n",
        "                file_path = os.path.join(path, f)\n",
        "                label = f.split('_')[4]\n",
        "                if label==select_label:\n",
        "                    data.append([file_path, 1])\n",
        "                else:\n",
        "                    data.append([file_path, 0])\n",
        "    return data\n",
        "\n",
        "train_data = prepare_data(path, train_patients, select_label)\n",
        "valid_data = prepare_data(path, valid_patients, select_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C27-Jjh7SAHN"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, batch_size=16, n_classes=8, image_size = 1024, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_classes = n_classes\n",
        "        self.image_size = image_size\n",
        "        self.dim = (image_size, image_size, 1)\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Generate data\n",
        "        data = [self.list_IDs[k][0] for k in indexes]\n",
        "        labels = [self.list_IDs[k][1] for k in indexes]\n",
        "        x, y = self.__data_generation(data,labels)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, data,labels):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        x = np.zeros((self.batch_size, *self.dim))\n",
        "        y = np.zeros((self.batch_size, self.n_classes))\n",
        "\n",
        "        # Generate data\n",
        "\n",
        "        for i, data_name in enumerate(data):\n",
        "            image = cv2.resize(cv2.imread(data_name,0), (self.image_size, self.image_size))/255.\n",
        "            x[i,:,:,0] = image[:]\n",
        "            y[i,labels[i]] = 1\n",
        "        return x,y\n",
        "\n",
        "train_generator = DataGenerator(list_IDs = train_data, n_classes=n_classes, batch_size=2, image_size=image_size, shuffle=True)\n",
        "valid_generator = DataGenerator(list_IDs = valid_data, n_classes=n_classes, batch_size=2, image_size=image_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CgYuIwubY_fr"
      },
      "outputs": [],
      "source": [
        "def Global_attention_block(inputs):\n",
        "    shape=K.int_shape(inputs)\n",
        "    x=AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
        "    x=Conv2D(shape[3],1, padding='same') (x)\n",
        "    x=Activation('relu') (x)\n",
        "    x=Conv2D(shape[3],1, padding='same') (x)\n",
        "    x=Activation('sigmoid') (x)\n",
        "    C_A=Multiply()([x,inputs])\n",
        "    \n",
        "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (C_A)\n",
        "    x=Activation('sigmoid') (x)\n",
        "\n",
        "    S_A=Multiply()([x,C_A])\n",
        "    return S_A\n",
        "\n",
        "def Category_attention_block(inputs,classes,k):\n",
        "    shape=K.int_shape(inputs)\n",
        "    F=Conv2D(k*classes,1, padding='same') (inputs)\n",
        "    F=BatchNormalization() (F)\n",
        "    F1=Activation('relu') (F)\n",
        "    \n",
        "    F2=F1\n",
        "    x=GlobalMaxPool2D()(F2)\n",
        "    \n",
        "    x=Reshape((classes,k)) (x)\n",
        "    S=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x)\n",
        "    \n",
        "    x=Reshape((shape[1],shape[2],classes,k)) (F1)\n",
        "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x)\n",
        "    x=Multiply()([S,x])\n",
        "    M=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (x)\n",
        "    \n",
        "    semantic=Multiply()([inputs,M])\n",
        "    return semantic\n",
        "\n",
        "# base_model= MobileNet(weights=None, include_top=False, input_shape=(image_size,image_size,1))\n",
        "base_model= EfficientNetB0(weights=None, include_top=False, input_shape=(image_size,image_size,1))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "all_layers = [layer.output for layer in base_model.layers]\n",
        "\n",
        "k = 3\n",
        "base_model_out= all_layers[-1] #-3\n",
        "\n",
        "GAB_out= Global_attention_block(base_model_out)\n",
        "CAB_out= Category_attention_block(GAB_out, 2, k)\n",
        "CAB_out= GlobalAveragePooling2D()(CAB_out)\n",
        "CAB_out= Dropout(0.5)(CAB_out)\n",
        "out= Dense(2, activation= 'softmax')(CAB_out)\n",
        "# Create Model\n",
        "model= Model(base_model.input, out)\n",
        "optimizer = Adam(learning_rate= learning_rate)\n",
        "# model.compile(optimizer= optimizer, loss= 'categorical_crossentropy', metrics=['acc', AUC(), Recall(), Precision()])\n",
        "model.compile(optimizer= optimizer, loss= 'categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AszuIjdsY_ar",
        "outputId": "faf10878-d156-485f-d81a-b9af882eff56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Result for Label 0\n",
            "Epoch 1/5\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.6997 - acc: 0.4960\n",
            "Epoch 1: val_loss improved from inf to 0.68969, saving model to model_0_weights.h5\n",
            "248/248 [==============================] - 221s 633ms/step - loss: 0.6997 - acc: 0.4960 - val_loss: 0.6897 - val_acc: 0.5526 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.5262\n",
            "Epoch 2: val_loss did not improve from 0.68969\n",
            "248/248 [==============================] - 163s 656ms/step - loss: 0.6939 - acc: 0.5262 - val_loss: 0.6917 - val_acc: 0.5526 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.5161\n",
            "Epoch 3: val_loss did not improve from 0.68969\n",
            "248/248 [==============================] - 162s 648ms/step - loss: 0.6932 - acc: 0.5161 - val_loss: 0.6910 - val_acc: 0.5526 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.6933 - acc: 0.5101\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.68969\n",
            "248/248 [==============================] - 155s 624ms/step - loss: 0.6933 - acc: 0.5101 - val_loss: 0.6908 - val_acc: 0.5526 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.6929 - acc: 0.5161\n",
            "Epoch 5: val_loss did not improve from 0.68969\n",
            "248/248 [==============================] - 161s 649ms/step - loss: 0.6929 - acc: 0.5161 - val_loss: 0.6903 - val_acc: 0.5526 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "print('Train Result for Label {}'.format(select_label))\n",
        "lr_decay= ReduceLROnPlateau(monitor= 'val_acc', factor= 0.5, patience= 3, verbose= 1)\n",
        "save_model= ModelCheckpoint('model_{}_weights.h5'.format(select_label), monitor= 'val_loss', verbose= 1, save_best_only= True)\n",
        "# earlystop = EarlyStopping(monitor='val_loss', patience=24, verbose=0)\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data= valid_generator,\n",
        "                    epochs= epochs,\n",
        "                    workers= 2,\n",
        "                    callbacks= [lr_decay,save_model],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xORkrGjJ9u3i"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, metric, select_label):\n",
        "    plt.plot(history.history[metric])\n",
        "    plt.plot(history.history['val_'+metric])\n",
        "    \n",
        "    plt.title('model {}'.format(metric))\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.savefig('label {} {}.png'.format(select_label, metric))\n",
        "    plt.close()\n",
        "\n",
        "for metrics in ['loss', 'acc']:\n",
        "    plot_history(history, metrics, select_label)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
