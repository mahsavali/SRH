{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e56cf64",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'patches500'\n",
        "batch_size = 16\n",
        "class_names = {'non-tumor': 0,\n",
        "               'adenocarcinoma': 1,\n",
        "               'hematopoietic ': 2,\n",
        "               'squamous cell carcinoma ': 3,\n",
        "               'melanoma': 4,\n",
        "               'neuroendocrine carcinoma ': 5,\n",
        "               'sarcoma ': 6,\n",
        "               'urothelial carcinoma ': 7,}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4396f544",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-13T02:01:18.151561Z",
          "iopub.status.busy": "2023-05-13T02:01:18.150920Z",
          "iopub.status.idle": "2023-05-13T02:01:18.556166Z",
          "shell.execute_reply": "2023-05-13T02:01:18.554804Z"
        },
        "id": "4396f544"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from collections import Counter\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2, os\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet18, mobilenet_v2\n",
        "from torcheval.metrics import MulticlassAccuracy\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "74094cbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_flatten(lis):\n",
        "    flatList = []\n",
        "    for element in lis:\n",
        "        if type(element) is list:\n",
        "            for item in element:\n",
        "                flatList.append(item)\n",
        "        else:\n",
        "            flatList.append(element)\n",
        "    return flatList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83875fa0",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_json('train_df.json')\n",
        "valid_df = pd.read_json('valid_df.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "06b71c38",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['label'] = train_df['patches'].apply(lambda x: x.split('_')[-1])\n",
        "valid_df['label'] = valid_df['patches'].apply(lambda x: x.split('_')[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "293f239e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def patch_split(df):\n",
        "    patches = []\n",
        "    for i in range(len(df)):\n",
        "        count_patches = df['count_patches'][i]\n",
        "        count_patches = count_patches%batch_size\n",
        "        temp = df['path'][i]\n",
        "        if count_patches!=0:\n",
        "            count_patches = batch_size - count_patches\n",
        "            temp = temp + temp[-count_patches:]\n",
        "        for j in range(0,len(temp),16):\n",
        "            patches.append(temp[j:j+16])\n",
        "    return patches\n",
        "\n",
        "train_patches , valid_patches = [] , []\n",
        "\n",
        "train_patches = patch_split(train_df)\n",
        "valid_patches = patch_split(valid_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "08594f20",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndf = pd.DataFrame(train_patients, columns=['files'])\\ndf['label'] = df['files'].apply(lambda x: int(x.split('_')[4]))\\n\\ncounter = Counter(df['label'])\\nmax_val = float(max(counter.values()))\\n\\ncounter = Counter(df['label'])\\nmax_val = float(max(counter.values()))\\nclass_weights = [max_val/num_images for _, num_images in counter.items()]\\n\\nclass_weights = torch.FloatTensor(class_weights).to('cuda')\\n\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "df = pd.DataFrame(train_patients, columns=['files'])\n",
        "df['label'] = df['files'].apply(lambda x: int(x.split('_')[4]))\n",
        "\n",
        "counter = Counter(df['label'])\n",
        "max_val = float(max(counter.values()))\n",
        "\n",
        "counter = Counter(df['label'])\n",
        "max_val = float(max(counter.values()))\n",
        "class_weights = [max_val/num_images for _, num_images in counter.items()]\n",
        "\n",
        "class_weights = torch.FloatTensor(class_weights).to('cuda')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7e4228e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_changer = {0:0, \n",
        "                1:1, 2:1, 3:1, 4:1, 5:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "49386e01",
      "metadata": {},
      "outputs": [],
      "source": [
        "class DATASET(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, batch_size, class_name):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.class_name = class_name\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = np.zeros((self.batch_size,3,224,224), dtype='float32')\n",
        "        for j in range(self.batch_size):\n",
        "            temp = cv2.cvtColor(cv2.imread(self.data[i][j]), cv2.COLOR_BGR2RGB)/255\n",
        "            image[j] = temp.transpose(2, 0, 1)\n",
        "\n",
        "        label = int(self.data[i][0].split('_')[4])\n",
        "        label = self.class_name[label]\n",
        "        target = np.zeros((2))\n",
        "        target[label] = 1\n",
        "        target = target.astype('float32')\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "train_dataset= DATASET(train_patches, batch_size, class_changer)\n",
        "valid_dataset = DATASET(valid_patches, batch_size, class_changer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=6)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6697c9c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Attn_Net(nn.Module):\n",
        "\n",
        "    def __init__(self, L = 1280, D = 256, dropout = False, n_classes = 1):\n",
        "        super(Attn_Net, self).__init__()\n",
        "        self.module = [\n",
        "            nn.Linear(L, D),\n",
        "            nn.Tanh()]\n",
        "\n",
        "        if dropout:\n",
        "            self.module.append(nn.Dropout(0.25))\n",
        "\n",
        "        self.module.append(nn.Linear(D, n_classes))\n",
        "        \n",
        "        self.module = nn.Sequential(*self.module)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.module(x), x # N x n_classes\n",
        "\n",
        "\"\"\"\n",
        "Attention Network with Sigmoid Gating (3 fc layers)\n",
        "args:\n",
        "    L: input feature dimension\n",
        "    D: hidden layer dimension\n",
        "    dropout: whether to use dropout (p = 0.25)\n",
        "    n_classes: number of classes \n",
        "\"\"\"\n",
        "class Attn_Net_Gated(nn.Module):\n",
        "    def __init__(self, L = 1280, D = 256, dropout = False, n_classes = 1):\n",
        "        super(Attn_Net_Gated, self).__init__()\n",
        "        self.attention_a = [\n",
        "            nn.Linear(L, D),\n",
        "            nn.Tanh()]\n",
        "        \n",
        "        self.attention_b = [nn.Linear(L, D),\n",
        "                            nn.Sigmoid()]\n",
        "        if dropout:\n",
        "            self.attention_a.append(nn.Dropout(0.25))\n",
        "            self.attention_b.append(nn.Dropout(0.25))\n",
        "\n",
        "        self.attention_a = nn.Sequential(*self.attention_a)\n",
        "        self.attention_b = nn.Sequential(*self.attention_b)\n",
        "        \n",
        "        self.attention_c = nn.Linear(D, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        a = self.attention_a(x)\n",
        "        b = self.attention_b(x)\n",
        "        A = a.mul(b)\n",
        "        A = self.attention_c(A)  # N x n_classes\n",
        "        return A, x\n",
        "\n",
        "\"\"\"\n",
        "args:\n",
        "    gate: whether to use gated attention network\n",
        "    size_arg: config for network size\n",
        "    dropout: whether to use dropout\n",
        "    k_sample: number of positive/neg patches to sample for instance-level training\n",
        "    dropout: whether to use dropout (p = 0.25)\n",
        "    n_classes: number of classes \n",
        "    instance_loss_fn: loss function to supervise instance-level training\n",
        "    subtyping: whether it's a subtyping problem\n",
        "\"\"\"\n",
        "class CLAM_SB(nn.Module):\n",
        "    def __init__(self, gate = True, size_arg = \"small\", dropout = False, k_sample=16, n_classes=2,\n",
        "        instance_loss_fn=nn.CrossEntropyLoss(), subtyping=False):\n",
        "        super(CLAM_SB, self).__init__()\n",
        "\n",
        "        resnet = mobilenet_v2(weights=None)\n",
        "        # for p in resnet.parameters():\n",
        "        #     p.requires_grad = False\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-1], nn.AvgPool2d(7,7), nn.Flatten())\n",
        "\n",
        "        self.size_dict = {\"small\": [1280, 512, 256], \"big\": [1280, 512, 384]}\n",
        "        size = self.size_dict[size_arg]\n",
        "        fc = [nn.Linear(size[0], size[1]), nn.ReLU()]\n",
        "        if dropout:\n",
        "            fc.append(nn.Dropout(0.25))\n",
        "        if gate:\n",
        "            attention_net = Attn_Net_Gated(L = size[1], D = size[2], dropout = dropout, n_classes = 1)\n",
        "        else:\n",
        "            attention_net = Attn_Net(L = size[1], D = size[2], dropout = dropout, n_classes = 1)\n",
        "        fc.append(attention_net)\n",
        "        self.attention_net = nn.Sequential(*fc)\n",
        "        self.classifiers = nn.Linear(size[1], n_classes)\n",
        "        instance_classifiers = [nn.Linear(size[1], 2) for i in range(n_classes)]\n",
        "        self.instance_classifiers = nn.ModuleList(instance_classifiers)\n",
        "        self.k_sample = k_sample\n",
        "        self.instance_loss_fn = instance_loss_fn\n",
        "        self.n_classes = n_classes\n",
        "        self.subtyping = subtyping\n",
        "\n",
        "        # initialize_weights(self)\n",
        "\n",
        "    def relocate(self):\n",
        "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.attention_net = self.attention_net.to(device)\n",
        "        self.classifiers = self.classifiers.to(device)\n",
        "        self.instance_classifiers = self.instance_classifiers.to(device)\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_positive_targets(length, device):\n",
        "        return torch.full((length, ), 1, device=device).long()\n",
        "    @staticmethod\n",
        "    def create_negative_targets(length, device):\n",
        "        return torch.full((length, ), 0, device=device).long()\n",
        "    \n",
        "    #instance-level evaluation for in-the-class attention branch\n",
        "    def inst_eval(self, A, h, classifier): \n",
        "        device=h.device\n",
        "        if len(A.shape) == 1:\n",
        "            A = A.view(1, -1)\n",
        "        top_p_ids = torch.topk(A, self.k_sample)[1][-1]\n",
        "        top_p = torch.index_select(h, dim=0, index=top_p_ids)\n",
        "        top_n_ids = torch.topk(-A, self.k_sample, dim=1)[1][-1]\n",
        "        top_n = torch.index_select(h, dim=0, index=top_n_ids)\n",
        "        p_targets = self.create_positive_targets(self.k_sample, device)\n",
        "        n_targets = self.create_negative_targets(self.k_sample, device)\n",
        "\n",
        "        all_targets = torch.cat([p_targets, n_targets], dim=0)\n",
        "        all_instances = torch.cat([top_p, top_n], dim=0)\n",
        "        logits = classifier(all_instances)\n",
        "        all_preds = torch.topk(logits, 1, dim = 1)[1].squeeze(1)\n",
        "        instance_loss = self.instance_loss_fn(logits, all_targets)\n",
        "        return instance_loss, all_preds, all_targets\n",
        "    \n",
        "    #instance-level evaluation for out-of-the-class attention branch\n",
        "    def inst_eval_out(self, A, h, classifier):\n",
        "        device=h.device\n",
        "        if len(A.shape) == 1:\n",
        "            A = A.view(1, -1)\n",
        "        top_p_ids = torch.topk(A, self.k_sample)[1][-1]\n",
        "        top_p = torch.index_select(h, dim=0, index=top_p_ids)\n",
        "        p_targets = self.create_negative_targets(self.k_sample, device)\n",
        "        logits = classifier(top_p)\n",
        "        p_preds = torch.topk(logits, 1, dim = 1)[1].squeeze(1)\n",
        "        instance_loss = self.instance_loss_fn(logits, p_targets)\n",
        "        return instance_loss, p_preds, p_targets\n",
        "\n",
        "    def forward(self, h, label=None, instance_eval=False, return_features=False, attention_only=False):\n",
        "        device = h.device\n",
        "        h = self.features(h)\n",
        "        A, h = self.attention_net(h)  # NxK        \n",
        "        A = torch.transpose(A, 1, 0)  # KxN\n",
        "        if attention_only:\n",
        "            return A\n",
        "        A_raw = A\n",
        "        A = F.softmax(A, dim=1)  # softmax over N\n",
        "\n",
        "        if instance_eval:\n",
        "            total_inst_loss = 0.0\n",
        "            all_preds = []\n",
        "            all_targets = []\n",
        "            inst_labels = F.one_hot(label, num_classes=self.n_classes).squeeze() #binarize label\n",
        "            for i in range(len(self.instance_classifiers)):\n",
        "                inst_label = inst_labels[i].item()\n",
        "                classifier = self.instance_classifiers[i]\n",
        "                if inst_label == 1: #in-the-class:\n",
        "                    instance_loss, preds, targets = self.inst_eval(A, h, classifier)\n",
        "                    all_preds.extend(preds.cpu().numpy())\n",
        "                    all_targets.extend(targets.cpu().numpy())\n",
        "                else: #out-of-the-class\n",
        "                    if self.subtyping:\n",
        "                        instance_loss, preds, targets = self.inst_eval_out(A, h, classifier)\n",
        "                        all_preds.extend(preds.cpu().numpy())\n",
        "                        all_targets.extend(targets.cpu().numpy())\n",
        "                    else:\n",
        "                        continue\n",
        "                total_inst_loss += instance_loss\n",
        "\n",
        "            if self.subtyping:\n",
        "                total_inst_loss /= len(self.instance_classifiers)\n",
        "                \n",
        "        M = torch.mm(A, h) \n",
        "        logits = self.classifiers(M)\n",
        "        Y_hat = torch.topk(logits, 1, dim = 1)[1]\n",
        "        Y_prob = F.softmax(logits, dim = 1)\n",
        "        if instance_eval:\n",
        "            results_dict = {'instance_loss': total_inst_loss, 'inst_labels': np.array(all_targets), \n",
        "            'inst_preds': np.array(all_preds)}\n",
        "        else:\n",
        "            results_dict = {}\n",
        "        if return_features:\n",
        "            results_dict.update({'features': M})\n",
        "        return logits, Y_prob, Y_hat, A_raw, results_dict\n",
        "        # return Y_prob\n",
        "\n",
        "model = CLAM_SB(n_classes=2, dropout=0.5, k_sample=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "aaeecf88",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "Train Loss: 0.2421, Acc 97.4392, Valid Loss: 0.1667, Acc 96.0317                                                                                                                                        \n",
            "Model saved.\n",
            "Adjusting learning rate of group 0 to 1.0000e-04.\n",
            "Train Loss: 0.1130, Acc 97.4392, Valid Loss: 0.1457, Acc 96.0317                                                                                                                                        \n",
            "Model saved.\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "Train Loss: 0.1043, Acc 97.4392, Valid Loss: 0.1569, Acc 96.0317                                                                                                                                        \n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "Train Loss: 0.0988, Acc 97.4392, Valid Loss: 0.1438, Acc 96.0317                                                                                                                                        \n",
            "Model saved.\n",
            "Adjusting learning rate of group 0 to 1.0000e-07.\n",
            "Train Loss: 0.0981, Acc 97.4392, Valid Loss: 0.1618, Acc 96.0317                                                                                                                                        \n",
            "Adjusting learning rate of group 0 to 1.0000e-08.\n",
            "Train Loss: 0.1009, Acc 97.4392, Valid Loss: 0.1604, Acc 96.0317                                                                                                                                        \n",
            "Adjusting learning rate of group 0 to 1.0000e-09.\n",
            "Train Loss: 0.1000, Acc 97.4392, Valid Loss: 0.1577, Acc 96.0317                                                                                                                                        \n",
            "Adjusting learning rate of group 0 to 1.0000e-10.\n",
            "Train Loss: 0.1067, Acc 97.2222, Progress: 76.06"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     29\u001b[0m \u001b[39m# train_acc = float(metric.update(predicted[1].argmax(dim=1), targets.argmax(dim=1)).compute())\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m y_pred\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m predicted[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49margmax(dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mtolist()\n\u001b[1;32m     31\u001b[0m y_true\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     32\u001b[0m train_acc \u001b[39m=\u001b[39m accuracy_score(y_true, y_pred)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "model = model.to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.001),])\n",
        "scheduler= torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1, verbose=True)\n",
        "\n",
        "epochs = 10\n",
        "counter = 1\n",
        "best_valid_loss = np.inf\n",
        "len_train_loader = len(train_loader)\n",
        "len_valid_loader = len(valid_loader)\n",
        "metric = MulticlassAccuracy(num_classes=2).to('cuda')\n",
        "history = [['train_loss', 'train_acc', 'valid_loss', 'valid_acc']]\n",
        "for i in range(1, epochs + 1):\n",
        "    running_loss = 0\n",
        "    model.train()\n",
        "    y_true, y_pred = [] , []\n",
        "    for batch_ind, (images, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        targets = targets.to('cuda')\n",
        "        predicted = model(images[0].to('cuda'))\n",
        "        loss = criterion(predicted[0], targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss\n",
        "\n",
        "        train_acc = float(metric.update(predicted[1].argmax(dim=1), targets.argmax(dim=1)).compute())\n",
        "        sys.stdout.write(\"\\rTrain Loss: {:<4.4f}, Acc {:<6.4f}, Progress: {:4.2f}\". format(running_loss/(batch_ind+1), train_acc*100, ((batch_ind+1)/len_train_loader)*100))\n",
        "        sys.stdout.flush()\n",
        "    train_loss = running_loss/len_train_loader\n",
        "    \n",
        "    y_true, y_pred = [] , []\n",
        "    # metric.reset()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0\n",
        "        model.eval()\n",
        "        for batch_ind, (images, targets) in enumerate(valid_loader):\n",
        "            predicted = model(images[0].to('cuda'))\n",
        "            targets = targets.to('cuda')\n",
        "            loss = criterion(predicted[0], targets)\n",
        "            running_loss += loss\n",
        "            valid_acc = float(metric.update(predicted[1].argmax(dim=1), targets.argmax(dim=1)).compute())\n",
        "            sys.stdout.write(\"\\rTrain Loss: {:4.4f}, Acc {:<6.4f}, Valid Loss: {:4.4f}, Acc {:<6.4f}, Progress: {:4.2f}\". format(train_loss, train_acc*100, running_loss/(batch_ind+1), valid_acc*100, ((batch_ind+1)/len_valid_loader)*100))\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        valid_loss = running_loss/len_valid_loader\n",
        "    # metric.reset()\n",
        "    sys.stdout.flush()\n",
        "    sys.stdout.write(\"\\r\"+\" \"*200)\n",
        "    sys.stdout.write(\"\\rTrain Loss: {:4.4f}, Acc {:<6.4f}, Valid Loss: {:4.4f}, Acc {:<6.4f}\".format(train_loss, train_acc*100, valid_loss, valid_acc*100))\n",
        "    sys.stdout.write(\"\\r\\n\")\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    history.append([float(train_loss), train_acc, float(valid_loss), valid_acc])\n",
        "    if valid_loss<best_valid_loss:\n",
        "        torch.save(model.state_dict(), 'weights.pth')\n",
        "        print('Model saved.')\n",
        "        best_valid_loss = valid_loss\n",
        "        counter=1\n",
        "    elif valid_loss>best_valid_loss:\n",
        "        counter+=1\n",
        "\n",
        "    if counter==3:\n",
        "        model.load_state_dict(torch.load('weights.pth'))\n",
        "        counter=1\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c76047de",
      "metadata": {},
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame(history[1:], columns=history[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dd404b4a",
      "metadata": {},
      "source": [
        "# plot metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e5e7341c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_history(df, metric):\n",
        "    plt.plot(df['train_'+metric])\n",
        "    plt.plot(df['valid_'+metric])\n",
        "\n",
        "    plt.title('model {}'.format(metric))\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'], loc='upper left')\n",
        "    plt.savefig('results/{}.png'.format(metric))\n",
        "    plt.close()\n",
        "\n",
        "for metrics in ['loss', 'acc']:\n",
        "    plot_history(history_df, metrics)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "87cadad4",
      "metadata": {},
      "source": [
        "# confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "9ac0f59d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class DATASET(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, batch_size, class_name):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.class_name = class_name\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = np.zeros((self.batch_size,3,224,224), dtype='float32')\n",
        "        for j in range(self.batch_size):\n",
        "            temp = cv2.cvtColor(cv2.imread(self.data[i][j]), cv2.COLOR_BGR2RGB)/255\n",
        "            image[j] = temp.transpose(2, 0, 1)\n",
        "\n",
        "        label = int(self.data[i][0].split('_')[4])\n",
        "        label = self.class_name[label]\n",
        "        target = np.zeros((2))\n",
        "        target[label] = 1\n",
        "        target = target.astype('float32')\n",
        "        return image, target, self.data[i][0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "valid_dataset = DATASET(valid_patches, batch_size, class_changer)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b565e809",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "patches500/10_img1_11_label_0_patch_00_.png\n",
            "patches500/10_img1_16_label_0_patch_00_.png\n",
            "patches500/10_img1_21_label_0_patch_00_.png\n",
            "patches500/10_img1_6_label_0_patch_00_.png\n",
            "patches500/10_img2_11_label_0_patch_00_.png\n",
            "patches500/10_img2_16_label_0_patch_00_.png\n",
            "patches500/10_img2_21_label_0_patch_00_.png\n",
            "patches500/10_img2_6_label_0_patch_00_.png\n",
            "patches500/10_img8_11_label_0_patch_00_.png\n",
            "patches500/10_img8_16_label_0_patch_00_.png\n",
            "patches500/10_img8_21_label_0_patch_00_.png\n",
            "patches500/10_img8_6_label_0_patch_00_.png\n",
            "patches500/10_img9_11_label_0_patch_00_.png\n",
            "patches500/10_img9_16_label_0_patch_00_.png\n",
            "patches500/10_img9_21_label_0_patch_00_.png\n",
            "patches500/10_img9_6_label_0_patch_00_.png\n",
            "patches500/11_img3_11_label_0_patch_00_.png\n",
            "patches500/11_img3_16_label_0_patch_00_.png\n",
            "patches500/11_img3_21_label_0_patch_00_.png\n",
            "patches500/11_img3_6_label_0_patch_00_.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('weights.pth'))\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes=2).to('cuda')\n",
        "y_true, y_pred = [] , []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch_ind, (images, targets, name) in enumerate(valid_loader):\n",
        "        predicted = model(images[0].to('cuda'))\n",
        "        targets = targets.to('cuda')\n",
        "        loss = criterion(predicted[0], targets)\n",
        "        running_loss += loss\n",
        "\n",
        "        valid_acc = float(metric.update(predicted[1].argmax(dim=1), targets.argmax(dim=1)).compute())\n",
        "\n",
        "        temp_pred = predicted[1].argmax(dim=1)\n",
        "        temp_true = targets.argmax(dim=1)\n",
        "\n",
        "        y_true.append(int(temp_true))\n",
        "        y_pred.append(int(temp_pred))\n",
        "\n",
        "        if temp_pred!=temp_true:\n",
        "            print(name[0])\n",
        "        # sys.stdout.write(\"\\rValid Loss: {:4.4f}, Acc {:<6.4f}, Progress: {:4.2f}\". format(running_loss/(batch_ind+1), valid_acc*100, ((batch_ind+1)/len_valid_loader)*100))\n",
        "        # sys.stdout.flush()\n",
        "\n",
        "\n",
        "disp= ConfusionMatrixDisplay.from_predictions(y_true= y_true,\n",
        "                                              y_pred= y_pred,\n",
        "                                              xticks_rotation= 45,\n",
        "                                              cmap='Blues', \n",
        "                                              display_labels=['non-tumor','tumor'],)\n",
        "\n",
        "disp.figure_.savefig('results/{}.png'.format('confusion_matrix'), bbox_inches = 'tight')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
